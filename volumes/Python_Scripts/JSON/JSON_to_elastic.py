import boto3
import json
import requests
from elasticsearch import Elasticsearch, helpers
import os
 
# --- 驻专 S3 ---
bucket_name = "naya-finalproject-json"
prefix = "PromotionDetails_json/"  #  拽爪 转拽 

# --- 转专转 -Elastic ---
index_name = "chain_index"
es = Elasticsearch("http://localhost:9200")
 
# --- 砖 1: 拽转 index 砖 ---
requests.delete(f"http://localhost:9200/{index_name}")
 
# --- 砖 2: 爪专转 index 砖 ---
requests.put(
    f"http://localhost:9200/{index_name}",
    json={"settings": {"number_of_shards": 1}}
)
 
# --- S3 client ---
AWS_DEFAULT_REGION = os.getenv("AWS_DEFAULT_REGION", "us-east-1")
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
s3 = boto3.client("s3",
                  aws_access_key_id=AWS_ACCESS_KEY_ID,
                  aws_secret_access_key=AWS_SECRET_ACCESS_KEY)
 
# --- 砖驻转 拽爪 转拽 ---
response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
 
def generate_actions_from_s3(key):
    """爪专 专专 砖专 住 -  注 专"""
    obj = s3.get_object(Bucket=bucket_name, Key=key)
    for line in obj["Body"].iter_lines():   # 拽专 专转 (streaming)
        if line:
            doc = json.loads(line.decode("utf-8"))
            yield {
                "_index": index_name,
                "_source": doc,
            }
 
# --- 砖 砖  拽爪 -bulk (专) ---
for obj in response.get("Contents", []):
    key = obj["Key"]
    if key.endswith(".json"):
        print(f"Uploading {key} ...")
        helpers.bulk(es, generate_actions_from_s3(key))
 
print("All NDJSON files uploaded successfully! ")